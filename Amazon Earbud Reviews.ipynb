{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import nltk\n",
    "import emoji\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout, LSTM, Conv1D, MaxPooling1D, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewTitle</th>\n",
       "      <th>ReviewBody</th>\n",
       "      <th>ReviewStar</th>\n",
       "      <th>Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honest review of an edm music lover\\n</td>\n",
       "      <td>No doubt it has a great bass and to a great ex...</td>\n",
       "      <td>3</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unreliable earphones with high cost\\n</td>\n",
       "      <td>This  earphones are unreliable, i bought it be...</td>\n",
       "      <td>1</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really good and durable.\\n</td>\n",
       "      <td>i bought itfor 999,I purchased it second time,...</td>\n",
       "      <td>4</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stopped working in just 14 days\\n</td>\n",
       "      <td>Its sound quality is adorable. overall it was ...</td>\n",
       "      <td>1</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just Awesome Wireless Headphone under 1000...ðŸ˜‰\\n</td>\n",
       "      <td>Its Awesome... Good sound quality &amp; 8-9 hrs ba...</td>\n",
       "      <td>5</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ReviewTitle  \\\n",
       "0             Honest review of an edm music lover\\n   \n",
       "1             Unreliable earphones with high cost\\n   \n",
       "2                        Really good and durable.\\n   \n",
       "3                 stopped working in just 14 days\\n   \n",
       "4  Just Awesome Wireless Headphone under 1000...ðŸ˜‰\\n   \n",
       "\n",
       "                                          ReviewBody  ReviewStar  \\\n",
       "0  No doubt it has a great bass and to a great ex...           3   \n",
       "1  This  earphones are unreliable, i bought it be...           1   \n",
       "2  i bought itfor 999,I purchased it second time,...           4   \n",
       "3  Its sound quality is adorable. overall it was ...           1   \n",
       "4  Its Awesome... Good sound quality & 8-9 hrs ba...           5   \n",
       "\n",
       "            Product  \n",
       "0  boAt Rockerz 255  \n",
       "1  boAt Rockerz 255  \n",
       "2  boAt Rockerz 255  \n",
       "3  boAt Rockerz 255  \n",
       "4  boAt Rockerz 255  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('AllProductReviews.csv')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the reviewTitle and ReviewBody columns into one\n",
    "reviews['review'] = reviews['ReviewTitle'] + reviews['ReviewBody']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_review = reviews['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = set(nltk.corpus.words.words())\n",
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = ' '.join([string for string in text if not string in sw])\n",
    "    text = re.sub(r'(?<=[.,])(?=[^\\s])', r' ', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation+'0123456789'))\n",
    "    text = ' '.join(text.split())\n",
    "    text = ''.join(string for string in text if string not in emoji.UNICODE_EMOJI)\n",
    "    text = \" \".join(w for w in nltk.wordpunct_tokenize(text) if w.lower() in word)\n",
    "    text = ' '.join([word for word in text.split() if len(word) > 2])\n",
    "    return text\n",
    "coll = complete_review.map(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert text into tokens with identitcal sequence length\n",
    "max_seq_length = 100\n",
    "vocab_size = 4000\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(coll)\n",
    "sequences = tokenizer.texts_to_sequences(coll)\n",
    "x_train = pad_sequences(sequences, maxlen=max_seq_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vector = reviews['ReviewStar'] - 1\n",
    "y_train = to_categorical(y_vector, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15712\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3584 samples, validate on 10753 samples\n",
      "Epoch 1/10\n",
      "3584/3584 [==============================] - 3s 764us/step - loss: 0.4063 - accuracy: 0.8214 - val_loss: 0.3540 - val_accuracy: 0.8485\n",
      "Epoch 2/10\n",
      "3584/3584 [==============================] - 3s 735us/step - loss: 0.3223 - accuracy: 0.8555 - val_loss: 0.3457 - val_accuracy: 0.8502\n",
      "Epoch 3/10\n",
      "3584/3584 [==============================] - 3s 716us/step - loss: 0.2548 - accuracy: 0.8945 - val_loss: 0.3595 - val_accuracy: 0.8440\n",
      "Epoch 4/10\n",
      "3584/3584 [==============================] - 3s 725us/step - loss: 0.1820 - accuracy: 0.9304 - val_loss: 0.3994 - val_accuracy: 0.8337\n",
      "Epoch 5/10\n",
      "3584/3584 [==============================] - 3s 719us/step - loss: 0.1226 - accuracy: 0.9567 - val_loss: 0.4493 - val_accuracy: 0.8161\n",
      "Epoch 6/10\n",
      "3584/3584 [==============================] - 3s 746us/step - loss: 0.0831 - accuracy: 0.9723 - val_loss: 0.4716 - val_accuracy: 0.8256\n",
      "Epoch 7/10\n",
      "3584/3584 [==============================] - 3s 713us/step - loss: 0.0603 - accuracy: 0.9800 - val_loss: 0.5001 - val_accuracy: 0.8298\n",
      "Epoch 8/10\n",
      "3584/3584 [==============================] - 3s 717us/step - loss: 0.0471 - accuracy: 0.9854 - val_loss: 0.5445 - val_accuracy: 0.8085\n",
      "Epoch 9/10\n",
      "3584/3584 [==============================] - 3s 724us/step - loss: 0.0388 - accuracy: 0.9884 - val_loss: 0.5630 - val_accuracy: 0.8262\n",
      "Epoch 10/10\n",
      "3584/3584 [==============================] - 3s 720us/step - loss: 0.0325 - accuracy: 0.9893 - val_loss: 0.5857 - val_accuracy: 0.8219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2574703fe48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the model architecture\n",
    "desired_embedding_size = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=desired_embedding_size,\n",
    "                    input_length = max_seq_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adagrad', loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_split=0.75, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 100)          400000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1280128   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 1,690,629\n",
      "Trainable params: 1,690,629\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
