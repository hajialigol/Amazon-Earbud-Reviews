{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import emoji\n",
    "import string\n",
    "import nltk\n",
    "from googletrans import Translator\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, Dropout, LSTM, Conv1D, MaxPooling1D, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewTitle</th>\n",
       "      <th>ReviewBody</th>\n",
       "      <th>ReviewStar</th>\n",
       "      <th>Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honest review of an edm music lover\\n</td>\n",
       "      <td>No doubt it has a great bass and to a great ex...</td>\n",
       "      <td>3</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Unreliable earphones with high cost\\n</td>\n",
       "      <td>This  earphones are unreliable, i bought it be...</td>\n",
       "      <td>1</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really good and durable.\\n</td>\n",
       "      <td>i bought itfor 999,I purchased it second time,...</td>\n",
       "      <td>4</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stopped working in just 14 days\\n</td>\n",
       "      <td>Its sound quality is adorable. overall it was ...</td>\n",
       "      <td>1</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just Awesome Wireless Headphone under 1000...ðŸ˜‰\\n</td>\n",
       "      <td>Its Awesome... Good sound quality &amp; 8-9 hrs ba...</td>\n",
       "      <td>5</td>\n",
       "      <td>boAt Rockerz 255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ReviewTitle  \\\n",
       "0             Honest review of an edm music lover\\n   \n",
       "1             Unreliable earphones with high cost\\n   \n",
       "2                        Really good and durable.\\n   \n",
       "3                 stopped working in just 14 days\\n   \n",
       "4  Just Awesome Wireless Headphone under 1000...ðŸ˜‰\\n   \n",
       "\n",
       "                                          ReviewBody  ReviewStar  \\\n",
       "0  No doubt it has a great bass and to a great ex...           3   \n",
       "1  This  earphones are unreliable, i bought it be...           1   \n",
       "2  i bought itfor 999,I purchased it second time,...           4   \n",
       "3  Its sound quality is adorable. overall it was ...           1   \n",
       "4  Its Awesome... Good sound quality & 8-9 hrs ba...           5   \n",
       "\n",
       "            Product  \n",
       "0  boAt Rockerz 255  \n",
       "1  boAt Rockerz 255  \n",
       "2  boAt Rockerz 255  \n",
       "3  boAt Rockerz 255  \n",
       "4  boAt Rockerz 255  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('Downloads\\AllProductReviews.csv')\n",
    "reviews = pd.read_csv('AllProductReviews.csv')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = reviews['ReviewTitle']\n",
    "body = reviews['ReviewBody']\n",
    "star = reviews['ReviewStar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the reviewTitle and ReviewBody columns into one\n",
    "reviews['review'] = reviews['ReviewTitle'] + reviews['ReviewBody']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_review = reviews['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = set(nltk.corpus.words.words())\n",
    "sw = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    text = ' '.join([string for string in text if not string in sw])\n",
    "    text = re.sub(r'(?<=[.,])(?=[^\\s])', r' ', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation+'0123456789'))\n",
    "    text = ' '.join(text.split())\n",
    "    text = ''.join(string for string in text if string not in emoji.UNICODE_EMOJI)\n",
    "    text = \" \".join(w for w in nltk.wordpunct_tokenize(text) if w.lower() in word)\n",
    "    text = ' '.join([word for word in text.split() if len(word) > 2])\n",
    "    return text\n",
    "coll = complete_review.map(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    honest review music lover doubt great bass gre...\n",
       "1    unreliable high cost unreliable bought days me...\n",
       "2    really good durable bought second time gifted ...\n",
       "3    stopped working days sound quality adorable ov...\n",
       "4    awesome wireless headphone awesome good sound ...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert text into tokens with identitcal sequence length\n",
    "max_seq_length = 100\n",
    "vocab_size = 4000\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(coll)\n",
    "sequences = tokenizer.texts_to_sequences(coll)\n",
    "x_train = pad_sequences(sequences, maxlen=max_seq_length, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vector = reviews['ReviewStar'] - 1\n",
    "y_train = to_categorical(y_vector, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0905 15:45:36.302284 14968 deprecation_wrapper.py:119] From C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0905 15:45:36.355823 14968 deprecation_wrapper.py:119] From C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0905 15:45:36.588410 14968 deprecation_wrapper.py:119] From C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0905 15:45:36.642844 14968 deprecation_wrapper.py:119] From C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0905 15:45:36.661822 14968 deprecation.py:506] From C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0905 15:45:36.665817 14968 nn_ops.py:4224] Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0905 15:45:36.830116 14968 deprecation_wrapper.py:119] From C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0905 15:45:36.881652 14968 deprecation_wrapper.py:119] From C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0905 15:45:37.176118 14968 deprecation.py:323] From C:\\Users\\danie\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10035 samples, validate on 4302 samples\n",
      "Epoch 1/10\n",
      "10035/10035 [==============================] - 8s 777us/step - loss: 1.1332 - acc: 0.5389 - val_loss: 0.9647 - val_acc: 0.6390\n",
      "Epoch 2/10\n",
      "10035/10035 [==============================] - 12s 1ms/step - loss: 0.9061 - acc: 0.6349 - val_loss: 0.9162 - val_acc: 0.6536\n",
      "Epoch 3/10\n",
      "10035/10035 [==============================] - 13s 1ms/step - loss: 0.8218 - acc: 0.6830 - val_loss: 0.9002 - val_acc: 0.6532\n",
      "Epoch 4/10\n",
      "10035/10035 [==============================] - 12s 1ms/step - loss: 0.7587 - acc: 0.7107 - val_loss: 0.8985 - val_acc: 0.6550\n",
      "Epoch 5/10\n",
      "10035/10035 [==============================] - 13s 1ms/step - loss: 0.7038 - acc: 0.7422 - val_loss: 0.8942 - val_acc: 0.6562\n",
      "Epoch 6/10\n",
      "10035/10035 [==============================] - 14s 1ms/step - loss: 0.6542 - acc: 0.7624 - val_loss: 0.8975 - val_acc: 0.6583\n",
      "Epoch 7/10\n",
      "10035/10035 [==============================] - 13s 1ms/step - loss: 0.6147 - acc: 0.7788 - val_loss: 0.8969 - val_acc: 0.6534\n",
      "Epoch 8/10\n",
      "10035/10035 [==============================] - 13s 1ms/step - loss: 0.5805 - acc: 0.7936 - val_loss: 0.9069 - val_acc: 0.6546\n",
      "Epoch 9/10\n",
      "10035/10035 [==============================] - 11s 1ms/step - loss: 0.5472 - acc: 0.8050 - val_loss: 0.9064 - val_acc: 0.6560\n",
      "Epoch 10/10\n",
      "10035/10035 [==============================] - 8s 845us/step - loss: 0.5196 - acc: 0.8173 - val_loss: 0.9205 - val_acc: 0.6516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2499a83a208>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the model architecture\n",
    "desired_embedding_size = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=desired_embedding_size,\n",
    "                    input_length = max_seq_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(rate=(0.6)))\n",
    "model.add(Dense(32, activation='tanh'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adagrad', loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, validation_split=0.3, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 100)          400000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 720,197\n",
      "Trainable params: 720,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
